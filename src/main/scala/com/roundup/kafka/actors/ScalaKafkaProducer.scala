package com.roundup.kafka.actors

import java.util.Properties

import kafka.utils.Logging
import org.apache.kafka.clients.producer.{RecordMetadata, Callback, KafkaProducer, ProducerRecord}
import org.apache.kafka.common.serialization.{ByteArraySerializer, StringSerializer}

/**
 * Created by Lior Gonnen on 3/16/15.
 */

/**
 * Wraps a Java Kafka Producer
 * @param brokers
 *        A list of host/port pairs to use for establishing the initial connection to the Kafka cluster. Data will be
 *        load balanced over all servers irrespective of which servers are specified here for bootstrappingâ€”this list
 *        only impacts the initial hosts used to discover the full set of servers. This list should be in the form
 *        host1:port1,host2:port2,.... Since these servers are just used for the initial connection to discover the full
 *        cluster membership (which may change dynamically), this list need not contain the full set of servers (you may
 *        want more than one, though, in case a server is down). If no server in this list is available sending data will
 *        fail until on becomes available.
 *
 * @param clientId
 *        The id string to pass to the server when making requests. The purpose of this is to be able to track the source
 *        of requests beyond just ip/port by allowing a logical application name to be included with the request.
 *        The application can set any string it wants as this has no functional purpose other than in logging and metrics.
 *
 * @param synchronously
 *        This parameter specifies whether the messages are sent asynchronously in a background thread.
 *        Valid values are false for asynchronous send and true for synchronous send. By setting the producer
 *        to async we allow batching together of requests (which is great for throughput) but open the possibility
 *        of a failure of the client machine dropping unsent data.
 *
 * @param compress
 *        If true, use GZip compression
 *        The compression type for all data generated by the producer. The default is none (i.e. no compression).
 *        Compression is of full batches of data, so the efficacy of batching will also impact the compression ratio
 *        (more batching means better compression).
 *
 * @param batchSize
 *        The producer will attempt to batch records together into fewer requests whenever multiple records are being sent
 *        to the same partition. This helps performance on both the client and the server. This configuration controls the
 *        default batch size in bytes. No attempt will be made to batch records larger than this size.
 *        Requests sent to brokers will contain multiple batches, one for each partition with data available to be sent.
 *        A small batch size will make batching less common and may reduce throughput (a batch size of zero will disable
 *        batching entirely). A very large batch size may use memory a bit more wastefully as we will always allocate a
 *        buffer of the specified batch size in anticipation of additional records.
 *
 * @param maxSendRetries
 *        Setting a value greater than zero will cause the client to resend any record whose send fails with a potentially
 *        transient error. Note that this retry is no different than if the client resent the record upon receiving the error.
 *        Allowing retries will potentially change the ordering of records because if two records are sent to a single partition,
 *        and the first fails and is retried but the second succeeds, then the second record may appear first.
 *
 * @param acks
 *        0 = The producer never waits for an acknowledgement from the broker (the same behavior as 0.7).
 *        This option provides the lowest latency but the weakest durability guarantees (some data will be lost when a server fails).
 *        1 = The producer gets an acknowledgement after the leader replica has received the data. This option provides
 *        better durability as the client waits until the server acknowledges the request as successful (only messages that were
 *        written to the now-dead leader but not yet replicated will be lost).
 *        -1 = The producer gets an acknowledgement after all in-sync replicas have received the data. This option
 *        provides the best durability, we guarantee that no messages will be lost as long as at least one in sync replica remains.
 *
 * @param requestTimeoutMillis
 *        The amount of time the broker will wait trying to meet the request.required.acks requirement before sending back an error
 *        to the client.
 *
 * @param bufferMemoryBytes
 *        The total bytes of memory the producer can use to buffer records waiting to be sent to the server.
 *         If records are sent faster than they can be delivered to the server the producer will either block or throw an exception based on
 *         the preference specified by block.on.buffer.full.
 *
 * @param metadataFetchTimeoutMillis
 *        he first time data is sent to a topic we must fetch metadata about that topic to know which servers host the topic's partitions.
 *        This configuration controls the maximum amount of time we will block waiting for the metadata fetch to succeed before throwing an
 *        exception back to the client.
 */

case class ProducerConfig(
    brokers: String = null,
    clientId: String = null,
    synchronously: Boolean = false,
    compress: Boolean = true,
    batchSize: Integer = 16384,
    maxSendRetries: Integer = 2,
    acks: Integer = 1,
    requestTimeoutMillis: Long = 2000,
    bufferMemoryBytes: Long = 10*1024*1024,
    metadataFetchTimeoutMillis: Long = 1000) {

    def validate = {
        require(brokers != null, "null brokers")
    }

    def toProperties = new Properties() {
        put("bootstrap.servers", brokers)
        put("buffer.memory", bufferMemoryBytes.toString)                // default=33554432
        put("retries", maxSendRetries.toString)                         // default=0
        put("acks", acks.toString)                                      // default=1
        put("compression.type", "gzip")                                 // default=none (none / gzip / snappy)
        put("batch.size", batchSize.toString)                           // default=16384
        put("request.timeout.ms", requestTimeoutMillis.toString)        // default=10000
        put("key.serializer", classOf[StringSerializer].getName)
        put("value.serializer", classOf[ByteArraySerializer].getName)
        put("producer.type", if(synchronously) "sync" else "async")
        put("metadata.fetch.timeout.ms", metadataFetchTimeoutMillis.toString)
        put("block.on.buffer.full", "false")
        if (clientId != null) put("client.id", clientId)
    }
}

case class ScalaKafkaProducer(config: ProducerConfig) extends Logging with Callback {

    require(config != null, "null config")

    config.validate

    val producer = new KafkaProducer[String, Array[Byte]](config.toProperties)

    def send(topic: String, message: String): Unit = send(topic, message.getBytes("UTF8"))

    def send(topic: String, message: Array[Byte]): Unit = producer.send(new ProducerRecord(topic, message), this)

    override def onCompletion(recordMetadata: RecordMetadata, e: Exception): Unit = {
        if (e != null) logger.error(e.getMessage)
    }

    def close: Unit = {
        try {
            producer.close()
        }
        catch {
            case e: Exception => error(e)
        }
    }
}